{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shd1994-DL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmq19950824/Deep-Learning/blob/master/shd1994_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rYsN-DAOTaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD2TVuRFzn6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pandas import read_csv\n",
        "\n",
        "# 导入数据并将分类转化为数字\n",
        "dataset = read_csv('BK.csv', delimiter=';')\n",
        "dataset['job'] = dataset['job'].replace(to_replace=['admin.', 'unknown', 'unemployed', 'management',\n",
        "                                                    'housemaid', 'entrepreneur', 'student', 'blue-collar',\n",
        "                                                    'self-employed', 'retired', 'technician', 'services'],\n",
        "                                        value=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "dataset['marital'] = dataset['marital'].replace(to_replace=['married', 'single', 'divorced'], value=[0, 1, 2])\n",
        "dataset['education'] = dataset['education'].replace(to_replace=['unknown', 'secondary', 'primary', 'tertiary'],\n",
        "                                                    value=[0, 2, 1, 3])\n",
        "dataset['default'] = dataset['default'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['housing'] = dataset['housing'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['loan'] = dataset['loan'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['contact'] = dataset['contact'].replace(to_replace=['cellular', 'unknown', 'telephone'], value=[0, 1, 2])\n",
        "dataset['poutcome'] = dataset['poutcome'].replace(to_replace=['unknown', 'other', 'success', 'failure'],\n",
        "                                                  value=[0, 1, 2, 3])\n",
        "dataset['month'] = dataset['month'].replace(to_replace=['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
        "                                                        'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
        "                                            value=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "dataset['y'] = dataset['y'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "\n",
        "# 分离输入输出\n",
        "array = dataset.values\n",
        "x = array[:, 0:16]\n",
        "Y = array[:, 16]\n",
        "\n",
        "# 设置随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(units_list=[16], optimizer='adam', init='normal'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "\n",
        "    # 构建第一个隐藏层和输入层\n",
        "    units = units_list[0]\n",
        "    model.add(Dense(units=units, activation='relu', input_dim=16, kernel_initializer=init))\n",
        "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init))\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=20)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, x, Y, cv=kfold)\n",
        "print('Accuracy: %.2f%% (%.2f)' % (results.mean() * 100, results.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1ae4g8jXvZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pandas import read_csv\n",
        "\n",
        "# 导入数据并将分类转化为数字\n",
        "dataset = read_csv('BK.csv', delimiter=';')\n",
        "dataset['job'] = dataset['job'].replace(to_replace=['admin.', 'unknown', 'unemployed', 'management',\n",
        "                                                    'housemaid', 'entrepreneur', 'student', 'blue-collar',\n",
        "                                                    'self-employed', 'retired', 'technician', 'services'],\n",
        "                                        value=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "dataset['marital'] = dataset['marital'].replace(to_replace=['married', 'single', 'divorced'], value=[0, 1, 2])\n",
        "dataset['education'] = dataset['education'].replace(to_replace=['unknown', 'secondary', 'primary', 'tertiary'],\n",
        "                                                    value=[0, 2, 1, 3])\n",
        "dataset['default'] = dataset['default'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['housing'] = dataset['housing'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['loan'] = dataset['loan'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['contact'] = dataset['contact'].replace(to_replace=['cellular', 'unknown', 'telephone'], value=[0, 1, 2])\n",
        "dataset['poutcome'] = dataset['poutcome'].replace(to_replace=['unknown', 'other', 'success', 'failure'],\n",
        "                                                  value=[0, 1, 2, 3])\n",
        "dataset['month'] = dataset['month'].replace(to_replace=['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
        "                                                        'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
        "                                            value=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "dataset['y'] = dataset['y'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "\n",
        "\n",
        "X = dataset.iloc[:, 0:16]\n",
        "Y = dataset.iloc[:, 16]\n",
        "\n",
        "# 设置随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(units_list=[30,8], optimizer='adam', init='normal'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "\n",
        "    # 构建第一个隐藏层和输入层\n",
        "    units = units_list[0]\n",
        "    model.add(Dense(units=units, activation='relu', input_dim=16, kernel_initializer=init))\n",
        "    for units in units_list[1:]:\n",
        "      model.add(Dense(units=units, activation='relu', kernel_initializer=init))\n",
        "    model.add(Dense(units=1, activation='sigmoid',kernel_initializer=init))\n",
        "    # 编译模型\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10)\n",
        "model.fit(X,Y)\n",
        "pred=model.predict_proba(X)\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model,X, Y, cv=kfold)\n",
        "print('Accuracy: %.2f%% (%.2f)' % (results.mean() * 100, results.std()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmcpqLxmGN6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y4V78CyrIB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pandas import read_csv\n",
        "\n",
        "# 导入数据并将分类转化为数字\n",
        "dataset = read_csv('BK.csv', delimiter=';')\n",
        "dataset['job'] = dataset['job'].replace(to_replace=['admin.', 'unknown', 'unemployed', 'management',\n",
        "                                                    'housemaid', 'entrepreneur', 'student', 'blue-collar',\n",
        "                                                    'self-employed', 'retired', 'technician', 'services'],\n",
        "                                        value=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "dataset['marital'] = dataset['marital'].replace(to_replace=['married', 'single', 'divorced'], value=[0, 1, 2])\n",
        "dataset['education'] = dataset['education'].replace(to_replace=['unknown', 'secondary', 'primary', 'tertiary'],\n",
        "                                                    value=[0, 2, 1, 3])\n",
        "dataset['default'] = dataset['default'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['housing'] = dataset['housing'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['loan'] = dataset['loan'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "dataset['contact'] = dataset['contact'].replace(to_replace=['cellular', 'unknown', 'telephone'], value=[0, 1, 2])\n",
        "dataset['poutcome'] = dataset['poutcome'].replace(to_replace=['unknown', 'other', 'success', 'failure'],\n",
        "                                                  value=[0, 1, 2, 3])\n",
        "dataset['month'] = dataset['month'].replace(to_replace=['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
        "                                                        'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
        "                                            value=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "dataset['y'] = dataset['y'].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
        "\n",
        "# 分离输入输出\n",
        "array = dataset.values\n",
        "x = array[:, 0:16]\n",
        "Y = array[:, 16]\n",
        "\n",
        "# 设置随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(units_list=[30,8], optimizer='adam', init='normal'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "\n",
        "    # 构建第一个隐藏层和输入层\n",
        "    units = units_list[0]\n",
        "    model.add(Dense(units=units, activation='relu', input_dim=16, kernel_initializer=init))\n",
        "    # 构建更多隐藏层\n",
        "    for units in units_list[1:]:\n",
        "        model.add(Dense(units=units, activation='relu', kernel_initializer=init))\n",
        "\n",
        "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init))\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "new_X = StandardScaler().fit_transform(X)\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, new_X, Y, cv=kfold)\n",
        "print('Accuracy: %.2f%% (%.2f)' % (results.mean() * 100, results.std()))\n",
        "\n",
        "# 调参选择最优模型\n",
        "param_grid = {}\n",
        "param_grid['units_list'] = [[16], [30], [16, 8], [30, 8]]\n",
        "# 调参\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)   #默认是3折交叉验证\n",
        "results = grid.fit(new_X, Y)\n",
        "\n",
        "pred1=results.predict_proba(new_X)\n",
        "\n",
        "# 输出结果\n",
        "print('Best: %f using %s' % (results.best_score_, results.best_params_))\n",
        "means = results.cv_results_['mean_test_score']\n",
        "stds = results.cv_results_['std_test_score']\n",
        "params = results.cv_results_['params']\n",
        "\n",
        "for mean, std, param in zip(means, stds, params):\n",
        "    print('%f (%f) with: %r' % (mean, std, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3dlTCHUaNWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import model_from_json\n",
        "\n",
        "\n",
        "# 导入数据\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "x = dataset.data\n",
        "Y = dataset.target\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "Y_labels = to_categorical(Y, num_classes=3)\n",
        "\n",
        "# 设定随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "# 构建模型函数\n",
        "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
        "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
        "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 构建模型\n",
        "model = create_model()\n",
        "model.fit(x, Y_labels, epochs=200, batch_size=5, verbose=2)\n",
        "\n",
        "scores = model.evaluate(x, Y_labels, verbose=1)\n",
        "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
        "\n",
        "# 模型保存成Json文件\n",
        "model_json = model.to_json()\n",
        "with open('../input/model.json', 'w') as file:\n",
        "    file.write(model_json)\n",
        "\n",
        "# 保存模型的权重值\n",
        "model.save_weights('../input/model.json.h5')\n",
        "\n",
        "\n",
        "# 从Json加载模型\n",
        "with open('../input/model.json', 'r') as file:\n",
        "    model_json = file.read()\n",
        "\n",
        "# 加载模型\n",
        "new_model = model_from_json(model_json)\n",
        "new_model.load_weights('../input/model.json.h5')\n",
        "\n",
        "# 编译模型\n",
        "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# 评估从Json加载的模型\n",
        "scores = new_model.evaluate(x, Y_labels, verbose=0)\n",
        "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V7gl2iAqlIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#隐藏层使用Dropout\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# 导入数据\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "x = dataset.data\n",
        "Y = dataset.target\n",
        "\n",
        "# 设定随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(init='glorot_uniform'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init, kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(rate=0.2))\n",
        "    model.add(Dense(units=6, activation='relu', kernel_initializer=init, kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(rate=0.2))\n",
        "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
        "\n",
        "    # 定义Dropout\n",
        "    sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, x, Y, cv=kfold)\n",
        "print('Accuracy: %.2f%% (%.2f)' % (results.mean()*100, results.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJcD9ZRIvECu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "# 导入数据\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "x = dataset.data\n",
        "Y = dataset.target\n",
        "\n",
        "# 设定随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(init='glorot_uniform'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
        "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
        "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
        "\n",
        "    #模型优化\n",
        "    learningRate = 0.1\n",
        "    momentum = 0.9\n",
        "    decay_rate = 0.005\n",
        "    sgd = SGD(lr=learningRate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "epochs = 200\n",
        "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=5, verbose=1)\n",
        "model.fit(x, Y)\n",
        "model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msBzIBvuxKbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from math import pow, floor\n",
        "\n",
        "\n",
        "# 导入数据\n",
        "dataset = datasets.load_iris()\n",
        "\n",
        "x = dataset.data\n",
        "Y = dataset.target\n",
        "\n",
        "# 设定随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 计算学习率\n",
        "def step_decay(epoch):\n",
        "    init_lrate = 0.1\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10\n",
        "    lrate = init_lrate * pow(drop, floor(1 + epoch) / epochs_drop)\n",
        "    return lrate\n",
        "\n",
        "# 构建模型函数\n",
        "def create_model(init='glorot_uniform'):\n",
        "    # 构建模型\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=4, activation='relu', input_dim=4, kernel_initializer=init))\n",
        "    model.add(Dense(units=6, activation='relu', kernel_initializer=init))\n",
        "    model.add(Dense(units=3, activation='softmax', kernel_initializer=init))\n",
        "\n",
        "    #模型优化\n",
        "    learningRate = 0.1\n",
        "    momentum = 0.9\n",
        "    decay_rate = 0.0\n",
        "    sgd = SGD(lr=learningRate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "\n",
        "    # 编译模型\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "epochs = 200\n",
        "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=5, verbose=1, callbacks=[lrate])\n",
        "model.fit(x, Y)\n",
        "model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXG5yXlf_-D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import np_utils\n",
        "from keras import backend\n",
        "backend.set_image_data_format('channels_first')\n",
        "\n",
        "# 设定随机种子\n",
        "seed = 7\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# 导入数据\n",
        "(X_train, y_train), (X_validation, y_validation) = cifar10.load_data()\n",
        "\n",
        "# 格式化数据到0-1之前\n",
        "X_train = X_train.astype('float32')\n",
        "X_validation = X_validation.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_validation = X_validation / 255.0\n",
        "\n",
        "# one-hot编码\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_validation = np_utils.to_categorical(y_validation)\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "def create_model(epochs=25):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    lrate = 0.01\n",
        "    decay = lrate / epochs\n",
        "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "epochs = 25\n",
        "model = create_model(epochs)\n",
        "model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=32, verbose=2)\n",
        "scores = model.evaluate(x=X_validation, y=y_validation, verbose=0)\n",
        "print('Accuracy: %.2f%%' % (scores[1] * 100))  #77.91%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj8J8LgOINnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import Dense,Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.initializers import RandomNormal\n",
        "from keras import optimizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "iterations = 391\n",
        "num_classes = 10\n",
        "dropout = 0.5\n",
        "\n",
        "\n",
        "def normalize_preprocessing(x_train, x_validation):\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_validation = x_validation.astype('float32')\n",
        "    mean = [125.307, 122.95, 113.865]\n",
        "    std = [62.9932, 62.0887, 66.7048]\n",
        "    for i in range(3):\n",
        "        x_train[:, :, :, i] = (x_train[:, :, :, i] - mean[i]) / std[i]\n",
        "        x_validation[:, :, :, i] = (x_validation[:, :, :, i] - mean[i]) / std[i]\n",
        "\n",
        "    return x_train, x_validation\n",
        "\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch <= 60:\n",
        "        return 0.05\n",
        "    if epoch <= 120:\n",
        "        return 0.01\n",
        "    if epoch <= 160:\n",
        "        return 0.002\n",
        "    return 0.0004\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(192, (5, 5), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.01), input_shape=x_train.shape[1:],\n",
        "                     activation='relu'))\n",
        "    model.add(Conv2D(160, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(Conv2D(96, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Conv2D(192, (5, 5), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(Conv2D(192, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(Conv2D(192, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(Conv2D(192, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "    model.add(Conv2D(10, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(0.0001),\n",
        "                     kernel_initializer=RandomNormal(stddev=0.05), activation='relu'))\n",
        "\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    np.random.seed(seed=7)\n",
        "    # load data\n",
        "    (x_train, y_train), (x_validation, y_validation) = cifar10.load_data()\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
        "\n",
        "    x_train, x_validation = normalize_preprocessing(x_train, x_validation)\n",
        "\n",
        "    # build network\n",
        "    model = build_model()\n",
        "    print(model.summary())\n",
        "\n",
        "    # set callback\n",
        "    change_lr = LearningRateScheduler(scheduler)\n",
        "    cbks = [change_lr]\n",
        "\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=cbks,\n",
        "              validation_data=(x_validation, y_validation), verbose=2)    #验证集上的精确率为88.94%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Dby3YMnbHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "bankfulldata=pd.read_csv('bkf.csv',sep=';')\n",
        "bankfulldata.shape\n",
        "bankfulldata.columns\n",
        "bankfulldata.iloc[1:5,]\n",
        "\n",
        "print(np.unique(bankfulldata['job']))\n",
        "print(np.unique(bankfulldata['marital']))\n",
        "print(np.unique(bankfulldata['education']))\n",
        "print(np.unique(bankfulldata['default']))\n",
        "print(np.unique(bankfulldata['housing']))\n",
        "print(np.unique(bankfulldata['loan']))\n",
        "print(np.unique(bankfulldata['contact']))\n",
        "print(np.unique(bankfulldata['month']))\n",
        "print(np.unique(bankfulldata['poutcome']))\n",
        "print(np.unique(bankfulldata['y']))\n",
        "#data preprocessing\n",
        "bankfulldata['job']=bankfulldata['job'].replace(['admin.','unknown','unemployed','management','housemaid','entrepreneur',\n",
        "'student','blue-collar','self-employed','retired','technician','services'],[0,1,2,3,4,5,6,7,8,9,10,11])\n",
        "bankfulldata['marital']=bankfulldata['marital'].replace(['married','single','divorced'],[0,1,2])\n",
        "bankfulldata['education']=bankfulldata['education'].replace(['unknown','secondary','primary','tertiary'],[0,2,1,3])\n",
        "bankfulldata['default']=bankfulldata['default'].replace(['no','yes'],[0,1])\n",
        "bankfulldata['housing']=bankfulldata['housing'].replace(['no','yes'],[0,1])\n",
        "bankfulldata['loan']=bankfulldata['loan'].replace(['no','yes'],[0,1])\n",
        "bankfulldata['contact']=bankfulldata['contact'].replace(['cellular','unknown','telephone'],[0,1,2])\n",
        "bankfulldata['month']=bankfulldata['month'].replace(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'],\n",
        "[1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "bankfulldata['poutcome']=bankfulldata['poutcome'].replace(['unknown','other','success','failure'],[0,1,2,3])\n",
        "bankfulldata['y']=bankfulldata['y'].replace(['no','yes'],[0,1])\n",
        "#split the data\n",
        "X=bankfulldata.iloc[:,0:16]\n",
        "Y=bankfulldata.iloc[:,16]\n",
        "\n",
        "random_state=np.random.seed(123)\n",
        "\n",
        "#Transform x into standardization data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_scaler=StandardScaler()\n",
        "X_scaler=X_scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LswpcI3WwSQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf1=LogisticRegression(C=1000,random_state=random_state)\n",
        "clf1.fit(X_scaler,Y)\n",
        "pred1=clf1.predict(X_scaler)\n",
        "pred_pro1=clf1.predict_proba(X_scaler)\n",
        "pred_pro1\n",
        "r1=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred1)],axis=1)\n",
        "1-sum(r1.iloc[:,0]!=r1.iloc[:,1])/X.shape[0]  #预测精确率 89.08%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCeKKo75nfAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------NB------------------------------------')\n",
        "from sklearn.naive_bayes  import GaussianNB\n",
        "clf2=GaussianNB()\n",
        "clf2.fit(X_scaler,Y)\n",
        "pred2=clf2.predict(X_scaler)\n",
        "pred_pro2=clf2.predict_proba(X_scaler)\n",
        "pred_pro2\n",
        "r2=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred2)],axis=1)\n",
        "1-sum(r2.iloc[:,0]!=r2.iloc[:,1])/X.shape[0]  #预测精确率 83.02%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBQ8fL93oFCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------SVC-----------------------------------')\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf3=SVC(C=10,kernel='rbf',probability=True,random_state=random_state)\n",
        "clf3.fit(X_scaler,Y)\n",
        "pred3=clf3.predict(X_scaler)\n",
        "pred_pro3=clf3.predict_proba(X_scaler)\n",
        "pred_pro3\n",
        "r3=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred3)],axis=1)\n",
        "1-sum(r3.iloc[:,0]!=r3.iloc[:,1])/X.shape[0]  #预测精确率 92.65%\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js8BZ7AloKt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------KNN------------------------------------')\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf4=KNeighborsClassifier(n_neighbors=12)\n",
        "clf4.fit(X_scaler,Y)\n",
        "pred4=clf4.predict(X_scaler)\n",
        "pred_pro4=clf4.predict_proba(X_scaler)\n",
        "pred_pro4\n",
        "r4=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred4)],axis=1)\n",
        "1-sum(r4.iloc[:,0]!=r4.iloc[:,1])/X.shape[0]  #预测精确率90.55%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMlMFde3oSvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------DT------------------------------------')\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf5=DecisionTreeClassifier(criterion='gini',max_depth=8,min_samples_leaf=4,random_state=random_state)\n",
        "clf5.fit(X_scaler,Y)\n",
        "pred5=clf5.predict(X_scaler)\n",
        "pred_pro5=clf5.predict_proba(X_scaler)\n",
        "pred_pro5\n",
        "r5=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred5)],axis=1)\n",
        "1-sum(r5.iloc[:,0]!=r5.iloc[:,1])/X.shape[0] #91.41%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08L9QI3EoXOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ensemble algorithms\n",
        "print('-----------------------------RF------------------------------------')\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf6=RandomForestClassifier(criterion='entropy',n_estimators=20,min_samples_leaf=5,random_state=random_state)#20\n",
        "clf6.fit(X_scaler,Y)\n",
        "pred6=clf6.predict(X_scaler)\n",
        "pred_pro6=clf6.predict_proba(X_scaler)\n",
        "pred_pro6\n",
        "r6=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred6)],axis=1)\n",
        "1-sum(r6.iloc[:,0]!=r6.iloc[:,1])/X.shape[0]  #94.94%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZt4nxH6odpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('----------------------ExtraTreesClassifier----------------------')\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "\n",
        "clf7=ExtraTreesClassifier(criterion='gini',n_estimators=10,min_samples_leaf=5,random_state=random_state) #gini+10\n",
        "clf7.fit(X_scaler,Y)\n",
        "pred7=clf7.predict(X_scaler)\n",
        "pred_pro7=clf7.predict_proba(X_scaler)\n",
        "pred_pro7\n",
        "r7=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred7)],axis=1)\n",
        "1-sum(r7.iloc[:,0]!=r7.iloc[:,1])/X.shape[0] #91.36%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MUaqa9QoiBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------AdaBoost---------------------------------')\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#参数训练有点奇怪\n",
        "clf8=AdaBoostClassifier(learning_rate=0.1,n_estimators=10,random_state=random_state)\n",
        "clf8.fit(X_scaler,Y)\n",
        "pred8=clf8.predict(X_scaler)\n",
        "pred_pro8=clf8.predict_proba(X_scaler)\n",
        "pred_pro8\n",
        "r8=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred8)],axis=1)\n",
        "1-sum(r8.iloc[:,0]!=r8.iloc[:,1])/X.shape[0] #88.30%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etJM0ONlqpkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GBDT与AdaBoost结果一样\n",
        "print('-----------------------------GBDT------------------------------------')\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "\n",
        "clf9=GradientBoostingClassifier(learning_rate=0.01,n_estimators=10,random_state=random_state)  #\n",
        "clf9.fit(X_scaler,Y)\n",
        "pred9=clf9.predict(X_scaler)\n",
        "pred_pro9=clf9.predict_proba(X_scaler)\n",
        "pred_pro9\n",
        "r9=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred9)],axis=1)\n",
        "1-sum(r9.iloc[:,0]!=r9.iloc[:,1])/X.shape[0]   #88.30%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZH8NZE2jQy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#define the grid search method\n",
        "def GridSearch(clf,params,X_scaler,Y):\n",
        "    #here we use two cores and 10-folds\n",
        "    model = GridSearchCV(clf, params, scoring='accuracy',cv=5,refit=True,verbose=2) #verbose=2表示输出完整日志信息\n",
        "    model.fit(X_scaler, Y)\n",
        "    #return the best estimator\n",
        "    return model.best_params_,model.best_estimator_\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XlzSMffjOxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "clf10=xgb.XGBClassifier(learning_rate=0.05,n_estimators=50,random_state=123)\n",
        "clf10.fit(X_scaler,Y)\n",
        "pred10=clf10.predict(X_scaler)\n",
        "pred_pro10=clf10.predict_proba(X_scaler)\n",
        "pred_pro10\n",
        "r10=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred10)],axis=1)\n",
        "1-sum(r10.iloc[:,0]!=r10.iloc[:,1])/X.shape[0]  #89.84%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXlUIxfQomdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------LightGBM----------------------------------')\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "clf11=lgb.LGBMClassifier(learning_rate=0.01,n_estimators=10,random_state=random_state)\n",
        "clf11.fit(X_scaler,Y)\n",
        "pred11=clf11.predict(X_scaler)\n",
        "pred_pro11=clf11.predict_proba(X_scaler)\n",
        "pred_pro11\n",
        "r11=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred11)],axis=1)\n",
        "1-sum(r11.iloc[:,0]!=r11.iloc[:,1])/X.shape[0]  #88.30%\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2FERS6xrKGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LagYVoD5ookJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print('-----------------------------CatBoost----------------------------------') #运算前需要先安装catboost\n",
        "import catboost as cb\n",
        "\n",
        "\n",
        "clf12=cb.CatBoostClassifier(learning_rate=0.05,n_estimators=50,random_state=random_state)\n",
        "clf12.fit(X_scaler,Y)\n",
        "pred12=clf12.predict(X_scaler)\n",
        "pred_pro12=clf12.predict_proba(X_scaler)\n",
        "pred_pro12\n",
        "r12=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred12)],axis=1)\n",
        "1-sum(r12.iloc[:,0]!=r12.iloc[:,1])/X.shape[0] #90.19%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tOAwP5nwGXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FIqBXeFrV3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('-----------------------------Stacking---------------------------------')\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "stacking_clf=StackingCVClassifier([clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11,clf12],\n",
        "                                meta_classifier=LogisticRegression(C=10000),cv=5,use_probas=True,verbose=2)\n",
        "stacking_clf.fit(X_scaler,Y)\n",
        "pred_stacking=stacking_clf.predict(X_scaler)\n",
        "pred_proba_stacking=stacking_clf.predict_proba(X_scaler)\n",
        "pred_proba_stacking\n",
        "r_stacking=pd.concat([pd.DataFrame(Y),pd.DataFrame(pred_stacking)],axis=1)\n",
        "1-sum(r_stacking.iloc[:,0]!=r_stacking.iloc[:,1])/X.shape[0]   #94.65%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngmGYVgZDo0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#情感分析之IMDB影评\n",
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "(x_train, y_train),(x_validation,y_validation) = imdb.load_data()\n",
        "\n",
        "# 合并训练集和评估数据集\n",
        "x = np.concatenate((x_train, x_validation), axis=0)\n",
        "y = np.concatenate((y_train, y_validation), axis=0)\n",
        "\n",
        "print('x shape is %s, y shape is %s' % (x.shape, y.shape))\n",
        "print('Classes: %s' % np.unique(y))\n",
        "\n",
        "print('Total words: %s' % len(np.unique(np.hstack(x))))\n",
        "\n",
        "result = [len(word) for word in x]\n",
        "print('Mean: %.2f words (STD: %.2f)' %(np.mean(result), np.std(result)))\n",
        "\n",
        "# 图表展示\n",
        "plt.subplot(121)\n",
        "plt.boxplot(result)\n",
        "plt.subplot(122)\n",
        "plt.hist(result)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPTYGktn_xYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "seed = 7\n",
        "top_words = 5000\n",
        "max_words = 500\n",
        "out_dimension = 32\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "\n",
        "# 构建模型\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(top_words, out_dimension, input_length=max_words))\n",
        "    model.add(LSTM(units=100))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # 输出模型的概要信息\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    np.random.seed(seed=seed)\n",
        "    # 导入数据\n",
        "    (x_train, y_train), (x_validation, y_validation) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "    # 限定数据集的长度\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
        "    x_validation = sequence.pad_sequences(x_validation, maxlen=max_words)\n",
        "\n",
        "    # 生产模型并训练模型\n",
        "    model = build_model()\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)\n",
        "    scores = model.evaluate(x_validation, y_validation, verbose=2)\n",
        "    print('Accuracy: %.2f%%' % (scores[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}